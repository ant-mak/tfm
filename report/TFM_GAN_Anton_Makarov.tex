\documentclass[a4paper,12pt]{report}

\usepackage{graphicx}

\usepackage[english, spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage[nottoc]{tocbibind}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[linesnumbered, ruled, spanish]{algorithm2e}	
\usepackage{url}

\newtheorem{defn}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}
\newtheorem{obs}{Observación}
\newtheorem{prop}{Proposición}

\newenvironment{abstractpage}
{\cleardoublepage\vspace*{\fill}\thispagestyle{empty}}
{\vfill\cleardoublepage}
\newenvironment{abstractnew}[1]
{\bigskip\selectlanguage{#1}%
	\begin{center}\bfseries\abstractname\end{center}}
{\par\bigskip}
		
\textheight=25cm \addtolength{\topmargin}{-2.5cm}

\begin{document}
\thispagestyle{empty}
\begin{center}

{\large\bf UNIVERSIDAD COMPLUTENSE DE MADRID} \\
{\bf\small FACULTAD DE CIENCIAS MATEMÁTICAS}\\[0.35cm]
{\large\bf UNIVERSIDAD POLITÉCNICA DE MADRID}\\
{\bf\small ESCUELA TÉCNICA SUPERIOR DE INGENIEROS DE TELECOMUNICACIÓN}\\[1.2cm]

{\bf MÁSTER EN TRATAMIENTO ESTADÍSTICO COMPUTACIONAL DE LA INFORMACIÓN}\\[1.2cm]
\mbox{}



\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUCM} \hspace{2.5cm}
\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUPM} \\[1.2cm]



{\large\bf TRABAJO DE FIN DE MÁSTER}\\[2cm]


{\large\bf Redes Generativas Antagónicas}\\[1cm]%Insertar título correspondiente

{\large\bf Antón Makarov Samusev}\\[1.5cm]%Insertar


{\bf Director}\\[0.4cm]
{\bf Francisco Javier Yáñez Gestoso} \\[2cm]

{\bf Madrid, 2019}
\end{center}

\newpage %Página blanco siguiente a la portada
\thispagestyle{empty}
\mbox{}\newpage

\begin{abstractpage}
	\begin{abstractnew}{spanish}
	Resumen
	\end{abstractnew}
	
	\begin{abstractnew}{english}
	Abstract
	\end{abstractnew}
\end{abstractpage}

\newpage %Página blanco siguiente a Resumen/Abstract
\thispagestyle{empty}
\mbox{}\newpage

\tableofcontents

\newpage %Página blanco siguiente a Índice
\thispagestyle{empty}
\mbox{}\newpage

\chapter{Introducción}
Introducción\footnote{Todo el código de este trabajo se puede encontrar en el repositorio de GitHub \url{https://github.com/ant-mak/tfm}, donde se incluyen las instrucciones para la reproducción de los resultados del proyecto.} \cite{goodfellow2014generative}, \cite{goodfellow2016nips}, \cite{radford2015unsupervised}, \cite{Goodfellow-et-al-2016}

\chapter{Preliminares}

\section{Conceptos básicos}
\begin{defn}[Divergencia de Kullback-Leibler]
	KL div
\end{defn}
\begin{defn}[Divergencia de Jensen-Shannon]
	JS div
\end{defn}
\begin{defn}[Equilibrio de Nash]
	Eq. Nash
\end{defn}
\section{Redes neuronales}

\subsection{Aprendizaje profundo}

\subsection{Redes neuronales convolucionales}

\chapter{Redes generativas antagónicas}
En este capítulo describiremos las ideas principales, tanto teóricas como prácticas de las redes generativas antagónicas, generative adversarial networks o GANs en inglés. Fueron propuestas por primera vez por Ian Goodfellow en 2014 \cite{goodfellow2014generative}, mezclando conceptos de aprendizaje automático no supervisado, supervisado y teoría de juegos. Desde entonces han suscitado una actividad investigadora muy importante. 
\section{Idea general}
El objetivo de las GANs es generar muestras de una distribución, cosa que a priori no parece complicado, existen métodos para generar muestras de variables aleatorias conocidas como por ejemplo la transformada inversa. Sin embargo, supongamos que queremos generar muestras de fotos de perros. Tenemos la seguridad de que la distribución es extremadamente compleja de describir, dado que hay perros de distintos colores, tamaños, razas, etc.

La idea fundamental de las GANs es poner dos redes neuronales a competir entre sí. Una red, llamada generadora $(G)$, está dedicada a obtener imágenes a partir de ruido, mientras que otra, llamada discriminadora $(D)$, trata de averiguar si la imagen es real o ficticia. Es frecuente ilustrar esta idea mediante la analogía de falsificadores de billetes que tratan de engañar a la policía. Los falsificadores empiezan dibujando billetes que no tienen nada que ver con los reales, intentando utilizarlos para pagar, momento en el que son atrapados por la policía. Los falsificadores por tanto se dan cuenta de que están dibujando mal y modifican su técnica, de manera que a lo largo del tiempo aprenden a burlar a la policía, que no es capaz de distinguir billetes reales de falsos. Una representación esquemática se puede ver en la Figura (\ref{esquema})
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{../images/report/scheme.png}
	\label{esquema}
	\caption{Diagrama conceptual de las redes generativas antagónicas.}
\end{figure}

El algoritmo genérico para el entrenamiento de este tipo de redes se describe en el Algoritmo \ref{alg:gan}.
\begin{algorithm}[h]
	\For{Iteraciones de entrenamiento}
	{
	Tomar muestra $(z^{(1)}, z^{(2)}, \ldots, z^{(m)})$ de tamaño $m$ de $p_g(z)$\;
	Tomar muestra $(x^{(1)}, x^{(2)}, \ldots, x^{(m)})$ de tamaño $m$ de $p_{data}(x)$\;
	Actualizar el discriminador ascendiendo su gradiente:
	$$
	\nabla_{\theta_d} \frac{1}{m}\sum_{i = 1}^{m}\left[\log D\left( x^{i}\right) + \log \left( 1 - D(G(z^{i}))\right) \right]
	$$
	
	Actualizar el generador ascendiendo su gradiente:
	$$
	\nabla_{\theta_g} \frac{1}{m}\sum_{i = 1}^{m} \log \left( 1 - D(G(z^{i}))\right)
	$$
	}
	\caption{Entrenamiento de una red generativa antagónica genérica.}
	\label{alg:gan}
\end{algorithm}
\section{Aspectos teóricos}
Veamos algunos de los resultados teóricos más relevantes:
\begin{teorema}
	Para un generador $G$ fijo, el discriminador $D$ óptimo es:
	\begin{equation}
	D_G^*(x) = \frac{p_{datos}(x)}{p_{datos}(x) + p_g(x)}
	\end{equation}
\end{teorema}
\begin{proof}
	El discriminador busca maximizar su función de utilidad, dada por $V(G,D)$
	\begin{equation}
	\begin{aligned}
	V(G,D) &= \int_x p_{datos}(x) \log (D(x)) \mathrm{d}x + \int_z p_z(z) \log(1-D(g(z))) \mathrm{d}z\\
	&= \int_x p_{datos}(x) \log (D(x)) + p_g(x) \log (1-D(x)) \mathrm{d}x
	\end{aligned}
	\end{equation}
\end{proof}

\section{Otros modelos generativos}
Variational autoencoders, noise contrastive estimation etc.
\chapter{Generación de arte}
En esta sección nos vamos a apoyar sobre el artículo \cite{radford2015unsupervised} para implementar en \texttt{PyTorch} una red convolucional profunda generativa antagónica, con la cual vamos a tratar de generar cuadros realistas.
\section{DCGAN}
Las redes convolucionales profundas generativas antagónicas (deep convolutional generative networks, DCGAN) son una extensión de las GANs tradicionales, que dan una serie de recomendaciones a la hora de implementarlas para incrementar la estabilidad y obtener imágenes de mejor calidad. Los puntos más relevantes mencionados en el artículo son:
\begin{itemize}
	\item En el discriminador, utilizar convoluciones con paso en lugar de capas de pooling.
	\item En el generador, utilizar convoluciones fraccionales con paso en vez de capas de pooling.
	\item Utilizar BatchNorm tanto para generador como discriminador.
	\item No utilizar capas fully connected
	\item Utilizar funciones de activación ReLU en el generador, salvo para la última capa, en la que se propone usar $\tanh$
	\item Utilizar funciones de activación LeakyReLU en el discriminador.
\end{itemize}
RECORDAR QUE STRIDE Y POOL SON PARECIDOS Y DESCRIBIR LEAKYRELU.

Como hemos dicho, nuestro objetivo es generar arte. Para ello vamos a necesitar un conjunto de datos con imágenes de una gran cantidad de cuadros. Dichas imágenes las hemos obtenido de unacompetición de Kaggle. Este conjunto de datos consta de aproximadamente 100000 imágenes, ocupando un total de 49 GB en el disco duro.

\section{Preprocesado}
El conjunto de datos tenía algunos defectos, como por ejemplo que había imágenes que no se descargaron correctamente o que el propio conjunto de datos tenía algunas muestras corruptas. Dichas imágenes las eliminamos.

Una vez hemos limpiado el conjunto de datos, es necesario realizar algunas transformaciones para que todo funcione como esperamos. En primer lugar hemos homogeneizado los tamaños y las proporciones. Pasamos así de cuadros de todos los tamaños y de distintas formas a cuadrados de $64\times 64$ píxeles. Posteriormente, les hacemos un recorte centrado y finalmente las cargamos como tensores.

\section{Arquitectura}
Siguiendo las recomendaciones del artículo \cite{radford2015unsupervised}, hemos decidido utilizar la arquitectura que se muestra en la Figura \ref{esqma}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{../images/report/architecture_scheme.png}
	\label{esqma}
	\caption{Arquitectura de las redes (Cambiar, poner tamaños de entrada y salida).}
\end{figure}
Se ha entrenado durante 30 épocas, utilizando el algoritmo de optimización Adam \cite{kingma2014adam} con una tasa de aprendizaje de $0.0002$.
\section{Resultados}
\subsection{Recursos}
Cabe destacar que ha sido imprescindible el uso de un ordenador con GPU compatible con CUDA, en concreto se ha utilizado una Nvidia Quadro P5000. El entrenamiento de principio a fin ha tardado aproximadamente 24 horas. También se han realizado pruebas con CPU en un portátil de prestaciones modestas y se ha observado que el rendimiento era unas 20 veces menor.
\chapter{Conclusión}


\bibliography{../bibliography/tfmbib}
\bibliographystyle{abbrv}
\end{document}
