\documentclass[a4paper,12pt]{report}

\usepackage{graphicx}

\usepackage[english, spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage[nottoc]{tocbibind}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[linesnumbered, ruled, spanish]{algorithm2e}	
\usepackage{url}

\newtheorem{defn}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}
\newtheorem{obs}{Observación}
\newtheorem{prop}{Proposición}

\newenvironment{abstractpage}
{\cleardoublepage\vspace*{\fill}\thispagestyle{empty}}
{\vfill\cleardoublepage}
\newenvironment{abstractnew}[1]
{\bigskip\selectlanguage{#1}%
	\begin{center}\bfseries\abstractname\end{center}}
{\par\bigskip}
		
\textheight=25cm \addtolength{\topmargin}{-2.5cm}

\begin{document}
\thispagestyle{empty}
\begin{center}

{\large\bf UNIVERSIDAD COMPLUTENSE DE MADRID} \\
{\bf\small FACULTAD DE CIENCIAS MATEMÁTICAS}\\[0.35cm]
{\large\bf UNIVERSIDAD POLITÉCNICA DE MADRID}\\
{\bf\small ESCUELA TÉCNICA SUPERIOR DE INGENIEROS DE TELECOMUNICACIÓN}\\[1.2cm]

{\bf MÁSTER EN TRATAMIENTO ESTADÍSTICO COMPUTACIONAL DE LA INFORMACIÓN}\\[1.2cm]
\mbox{}



\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUCM} \hspace{2.5cm}
\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUPM} \\[1.2cm]



{\large\bf TRABAJO DE FIN DE MÁSTER}\\[2cm]


{\large\bf Redes Generativas Antagónicas}\\[1cm]%Insertar título correspondiente

{\large\bf Antón Makarov Samusev}\\[1.5cm]%Insertar


{\bf Director}\\[0.4cm]
{\bf Francisco Javier Yáñez Gestoso} \\[2cm]

{\bf Madrid, 2019}
\end{center}

\newpage %Página blanco siguiente a la portada
\thispagestyle{empty}
\mbox{}\newpage

\begin{abstractpage}
	\begin{abstractnew}{spanish}
	Resumen
	\end{abstractnew}
	
	\begin{abstractnew}{english}
	Abstract
	\end{abstractnew}
\end{abstractpage}

\newpage %Página blanco siguiente a Resumen/Abstract
\thispagestyle{empty}
\mbox{}\newpage

\tableofcontents

\newpage %Página blanco siguiente a Índice
\thispagestyle{empty}
\mbox{}\newpage

\chapter{Introducción}
Introducción\footnote{Todo el código de este trabajo se puede encontrar en el repositorio de GitHub \url{https://github.com/ant-mak/tfm}, donde se incluyen las instrucciones para la reproducción de los resultados del proyecto.} \cite{goodfellow2014generative}, \cite{goodfellow2016nips}, \cite{radford2015unsupervised}, \cite{Goodfellow-et-al-2016}

\chapter{Preliminares}

\section{Conceptos básicos}
\begin{defn}[Divergencia de Kullback-Leibler]
	KL div
\end{defn}
\begin{defn}[Divergencia de Jensen-Shannon]
	JS div
\end{defn}
\begin{defn}[Equilibrio de Nash]
	Eq. Nash
\end{defn}
\section{Redes neuronales}

\subsection{Aprendizaje profundo}

\subsection{Redes neuronales convolucionales}

\chapter{Redes generativas antagónicas}
En este capítulo describiremos las ideas principales, tanto teóricas como prácticas de las redes generativas antagónicas, generative adversarial networks o GANs en inglés. Fueron propuestas por primera vez por Ian Goodfellow en 2014 \cite{goodfellow2014generative}, mezclando conceptos de aprendizaje automático no supervisado, supervisado y teoría de juegos. Desde entonces han suscitado una actividad investigadora muy importante, con aplicaciones en prácticamente todos los campos relacionados con el aprendizaje automático. 
\section{Idea general}
El objetivo de las GANs, y en general de los modelos generativos, es aprender la distribución que siguen los datos, pudiendo obtener así, en última instancia, muestras de dicha distribución. En general, las distribuciones que queremos modelar son muy complejas. Supongamos que nuestro objetivo es tomar muestras de la distribución de imágenes de perros, o dicho de otro modo, generar fotos de perros que sean realistas pero que no existan en la realidad ni sean una mezcla de imágenes de nuestro conjunto de entrenamiento. Tenemos la seguridad de que la distribución es extremadamente intrincada, existen perros de distintos colores, tamaños, razas, etc. Este problema es el que van a tratar de atacar las GANs.

La idea fundamental y más novedosa detrás de las GANs es poner dos redes neuronales a competir entre sí. Una red, llamada generadora $(G)$, está dedicada a obtener imágenes a partir de ruido aleatorio con distribución $p_g(z)$, mientras que otra, llamada discriminadora $(D)$, trata de averiguar si la imagen es real o ficticia. Es frecuente ilustrar esta idea mediante la analogía de falsificadores de billetes que tratan de engañar a la policía. Los falsificadores empiezan dibujando billetes que no tienen nada que ver con los reales, intentando utilizarlos para realizar pagos, momento en el que son atrapados por la policía. Los falsificadores por tanto se dan cuenta de que están dibujando los billetes de manera incorrecta y modifican su técnica, mientras que la policía va aprendiendo a su vez a detectar mejor los billetes falsos. De este modo, a lo largo del entrenamiento se busca llegar a un equilibrio, en el que la policía no sepa discernir los billetes falsos de los verdaderos, obteniendo así los ladrones una falsificación realista. Una representación esquemática se puede ver en la Figura (\ref{esquema})
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{../images/report/scheme.png}
	\label{esquema}
	\caption{Diagrama conceptual de las redes generativas antagónicas.}
\end{figure}
Podemos traducir esta idea a términos matemáticos de la siguiente manera:

Para aprender la distribución $p_g$ del generador sobre los datos $x$, definimos una distribución sobre las variables de ruido de entrada $p_z(z)$. Mediante un perceptrón multicapa con parámetros $\theta_g$ definimos la función $G(z;\theta_g)$. Definimos también mediante otro perceptrón multicapa $D(x; \theta_d)$ la probabilidad de que $x$ es una muestra de los datos y no del generador. Entrenamos $D$ para que maximice la probabilidad de asignar la etiqueta correcta tanto a los ejemplos de entrenamiento como a los generados. Al mismo tiempo, entrenamos $G$ para que minimice $\log (1- D(G(z)))$. Es decir, tenemos el siguiente juego minimax:
\begin{equation}
\min_G \max_D V(D,G) = \mathbb{E} [\log D(x)] + \mathbb{E} [\log (1- D(G(z)))].
\end{equation}

En el Algoritmo \ref{alg:gan} describimos lo anterior de manera más concisa y damos una primera idea de cómo se lleva a cabo el entrenamiento.
\begin{algorithm}[h]
	\For{Iteraciones de entrenamiento}
	{
	Tomar muestra $(z^{(1)}, z^{(2)}, \ldots, z^{(m)})$ de tamaño $m$ de $p_g(z)$\;
	Tomar muestra $(x^{(1)}, x^{(2)}, \ldots, x^{(m)})$ de tamaño $m$ de $p_{d}(x)$\;
	Actualizar el discriminador ascendiendo su gradiente:
	$$
	\nabla_{\theta_d} \frac{1}{m}\sum_{i = 1}^{m}\left[\log D\left( x^{i}\right) + \log \left( 1 - D(G(z^{i}))\right) \right]
	$$
	
	Actualizar el generador ascendiendo su gradiente:
	$$
	\nabla_{\theta_g} \frac{1}{m}\sum_{i = 1}^{m} \log \left( 1 - D(G(z^{i}))\right)
	$$
	}
	\caption{Entrenamiento de una red generativa antagónica genérica.}
	\label{alg:gan}
\end{algorithm}
\section{Bases teóricas}

En esta sección realizaremos un análisis de la teoría que hay detrás de las redes generativas antagónicas. Mostraremos que el criterio de entrenamiento nos permite recuperar la distribución de los datos si damos a $G$ y $D$ capacidad suficiente. 

\begin{teorema}
	Para un generador $G$ fijo, el discriminador $D$ óptimo es:
	\begin{equation}
	D_G^*(x) = \frac{p_{datos}(x)}{p_{datos}(x) + p_g(x)}
	\end{equation}
\end{teorema}
\begin{proof}
	El discriminador busca maximizar su función de utilidad, dada por $V(G,D)$
	\begin{equation}
	\begin{aligned}
	V(G,D) &= \int_x p_{datos}(x) \log (D(x)) \mathrm{d}x + \int_z p_z(z) \log(1-D(g(z))) \mathrm{d}z\\
	&= \int_x p_{datos}(x) \log (D(x)) + p_g(x) \log (1-D(x)) \mathrm{d}x
	\end{aligned}
	\end{equation}
\end{proof}

\section{Otros modelos generativos}
Variational autoencoders, noise contrastive estimation etc.
\chapter{Generación de arte}
En esta sección nos vamos a apoyar sobre el artículo \cite{radford2015unsupervised} para implementar en PyTorch una red convolucional profunda generativa antagónica, con la cual vamos a tratar de generar imágenes de cuadros realistas.
\section{DCGAN}
Las redes convolucionales profundas generativas antagónicas (deep convolutional generative adversarial networks, DCGAN) son una extensión de las GANs tradicionales, que dan una serie de recomendaciones a la hora de implementarlas para incrementar la estabilidad y obtener imágenes de mejor calidad. Los puntos más relevantes mencionados en el artículo son:
\begin{itemize}
	\item En el discriminador, utilizar convoluciones con stride en lugar de capas de pooling.
	\item En el generador, utilizar convoluciones fraccionales con stride en lugar de capas de pooling.
	\item Utilizar BatchNorm tanto para generador como discriminador.
	\item No utilizar capas fully connected.
	\item Utilizar funciones de activación ReLU en el generador, salvo para la última capa, en la que se propone usar $\tanh$.
	\item Utilizar funciones de activación LeakyReLU en el discriminador.
	\item Inicializar los pesos de ambas redes con una distribución normal.
\end{itemize}
RECORDAR QUE STRIDE Y POOL SON PARECIDOS Y DESCRIBIR LEAKYRELU.

El objetivo que nos hemos propuesto es la generación de cuadros realistas, para ello, es necesario un amplio conjunto de datos con cuadros de distintos artístas, épocas y estilos. Hemos encontrado en  una competición de Kaggle un conjunto de datos con las características deseadas, con más de 100000 imágenes, ocupando aproximadamente 49 GB. Una muestra de dichas imágenes se puede observar en la Figura \ref{img_reales}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{../images/results/original_data.png}
	\label{img_reales}
	\caption{Imágenes del conjunto de datos.}
\end{figure}

\subsection{Preprocesado}
El conjunto de datos tenía algunos defectos, como por ejemplo imágenes descargadas incorrectamente o imágenes corruptas en el propio conjunto de datos. Se ha tomado la decisión de eliminar dichas imágenes. ya que son pocas y no hay una manera directa de recuperarlas.

Una vez limpio el conjunto de datos, es necesario realizar algunas transformaciones para que, posteriormente, nuestras redes neuronales puedan utilizar las imágenes. En primer lugar hemos homogeneizado los tamaños y las proporciones. Pasamos así de cuadros de todos los tamaños y de distintas formas a cuadrados de $64\times 64$ píxeles. Posteriormente, realizamos un recorte centrado y finalmente las cargamos como tensores.

\subsection{Arquitectura}
Siguiendo las recomendaciones del artículo \cite{radford2015unsupervised}, hemos decidido utilizar la arquitectura que se muestra en la Figura \ref{esqma}. También hemos inicializado los pesos con una distribución normal $\mathcal{N}()$ y hemos seleccionado un tamaño de batch de 128.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{../images/report/architecture_scheme.png}
	\label{esqma}
	\caption{Arquitectura de las redes (Cambiar, poner tamaños de entrada y salida).}
\end{figure}
La red se ha entrenado durante 30 épocas, utilizando el algoritmo de optimización Adam \cite{kingma2014adam} con una tasa de aprendizaje de $0.0002$ y $\beta = (0.5,0.999)$.
\subsection{Recursos}
Cabe destacar que ha sido imprescindible el uso de un ordenador con GPU compatible con CUDA, en concreto se ha utilizado una Nvidia Quadro P5000. El entrenamiento de principio a fin ha tardado aproximadamente 24 horas. También se han realizado pruebas con CPU en un portátil de prestaciones modestas y se ha observado que el rendimiento era unas 20 veces menor.
\section{Resultados}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{../images/results/generated_data.png}
	\label{img_generadas}
	\caption{Imágenes generadas mediante la DCGAN implementada después de 30 épocas de entrenamiento.}
\end{figure}
\chapter{Conclusión}


\bibliography{../bibliography/tfmbib}
\bibliographystyle{abbrv}
\end{document}
