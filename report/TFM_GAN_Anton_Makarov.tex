\documentclass[a4paper,12pt]{report}

\usepackage{graphicx}

\usepackage[english, spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage[nottoc]{tocbibind}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[linesnumbered, ruled, spanish]{algorithm2e}	
\usepackage{url}

\newtheorem{defn}{Definición}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}
\newtheorem{obs}{Observación}
\newtheorem{prop}{Proposición}

\newenvironment{abstractpage}
{\cleardoublepage\vspace*{\fill}\thispagestyle{empty}}
{\vfill\cleardoublepage}
\newenvironment{abstractnew}[1]
{\bigskip\selectlanguage{#1}%
	\begin{center}\bfseries\abstractname\end{center}}
{\par\bigskip}
		
\textheight=25cm \addtolength{\topmargin}{-2.5cm}

\begin{document}
\thispagestyle{empty}
\begin{center}

{\large\bf UNIVERSIDAD COMPLUTENSE DE MADRID} \\
{\bf\small FACULTAD DE CIENCIAS MATEMÁTICAS}\\[0.35cm]
{\large\bf UNIVERSIDAD POLITÉCNICA DE MADRID}\\
{\bf\small ESCUELA TÉCNICA SUPERIOR DE INGENIEROS DE TELECOMUNICACIÓN}\\[1.2cm]

{\bf MÁSTER EN TRATAMIENTO ESTADÍSTICO COMPUTACIONAL DE LA INFORMACIÓN}\\[1.2cm]
\mbox{}



\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUCM} \hspace{2.5cm}
\includegraphics[scale=1.5]{../images/cover/TECI-EscudoUPM} \\[1.2cm]



{\large\bf TRABAJO DE FIN DE MÁSTER}\\[2cm]


{\large\bf Redes Generativas Antagónicas}\\[1cm]%Insertar título correspondiente

{\large\bf Antón Makarov Samusev}\\[1.5cm]%Insertar


{\bf Director}\\[0.4cm]
{\bf Francisco Javier Yáñez Gestoso} \\[2cm]

{\bf Madrid, 2019}
\end{center}

\newpage %Página blanco siguiente a la portada
\thispagestyle{empty}
\mbox{}\newpage

\begin{abstractpage}
	\begin{abstractnew}{spanish}
	Resumen
	\end{abstractnew}
	
	\begin{abstractnew}{english}
	Abstract
	\end{abstractnew}
\end{abstractpage}

\newpage %Página blanco siguiente a Resumen/Abstract
\thispagestyle{empty}
\mbox{}\newpage

\tableofcontents

\newpage %Página blanco siguiente a Índice
\thispagestyle{empty}
\mbox{}\newpage

\chapter{Introducción}
Introducción\footnote{Todo el código de este trabajo se puede encontrar en el repositorio de GitHub \url{https://github.com/ant-mak/tfm}, donde se incluyen las instrucciones para la reproducción de los resultados del proyecto.} \cite{goodfellow2014generative}, \cite{goodfellow2016nips}, \cite{radford2015unsupervised}, \cite{Goodfellow-et-al-2016}

\chapter{Preliminares}
En este capítulo realizaremos un breve resumen de los conceptos fundamentales del aprendizaje automático, introduciremos las definiciones necesarias para el desarrollo del resto del trabajo y daremos unas nociones básicas sobre aprendizaje profundo, haciendo hincapié en las redes convolucionales.
\section{Conceptos básicos}
\begin{defn}[Problemas en aprendizaje automático]
	hola
\end{defn}
\begin{defn}[Divergencia de Kullback-Leibler]
	KL div
\end{defn}
\begin{defn}[Divergencia de Jensen-Shannon]
	JS div
\end{defn}
\begin{defn}[Equilibrio de Nash]
	Eq. Nash
\end{defn}
\section{Redes neuronales}

\subsection{Aprendizaje profundo}
El aprendizaje profundo es un subgrupo de algoritmos de aprendizaje automático que buscan abstraer características de alto nivel presentes en los datos, utilizando generalmente, arquitecturas basadas en redes neuronales con una gran cantidad de capas.

En la actualidad son muy populares debido a su enorme potencial para resolver problemas complejos en ámbitos como la visión por computador o  el procesamiento del lenguaje natural, entre otros. Dicho potencial no ha podido ser aprovechado hasta hace muy poco debido a la escasez, por un lado, de conjuntos de datos adecuados y por otro, de recursos computacionales, ya que estos métodos requieren unas capacidades de cálculo y tamaños de conjuntos de datos muy superiores a otros métodos más tradicionales.
\subsection{Redes neuronales convolucionales}
Dado que nuestro objetivo es describir las redes generativas antagónicas y, más concretamente, utilizarlas para la generación de imágenes, es imprescindible introducir algunos de los conceptos más importantes de la familia de arquitecturas de aprendizaje profundo que están a la vanguardia en el campo de la visión por computador, las redes neuronales convolucionales (convolutional neural networks o CNNs en inglés).

Debemos sus primeros desarrollos a Kunihiko Fukushima, que en 1980 introdujo el neocognitrón \cite{fukushima1980}, que posteriormente sería tomado por Yann LeCun, que introdujo la mayoría de conceptos por los que conocemos este tipo de redes hoy en día.

La particularidad de las CNNs es que introducen una visión local del espacio. Pensemos en una imagen de un perro, parece razonable que intentemos identificar que efectivamente lo que vemos es un perro y no un gato fijándonos en pequeñas partes de la imagen como ojos, hocico, patas, orejas, etc. en lugar de todos los píxeles a la vez sin ningún tipo de relación espacial entre si. Es destacable que este tipo de filtros ya se hacían antes de las redes convolucionales, seleccionando regiones de interés manualmente. Sin embargo, las redes convolucionales van más allá, automatizando el proceso de extracción de características, aprendiendo durante el entrenamiento los filtros más idóneos.

Veamos ahora en detalle el funcionamiento de las redes convolucionales a la vez que desarrollamos los conceptos básicos que nos serán de utilidad a lo largo del resto del trabajo.
\begin{defn}[Capa convolucional]
	STRIDE
\end{defn}

\begin{defn}[Capa de Pooling]
	hola
\end{defn}

\begin{defn}[Capa de Batch Normalization]
	hola
\end{defn}

\begin{defn}[ReLU]
	hola
\end{defn}

\chapter{Redes generativas antagónicas}
En este capítulo describiremos las ideas principales, tanto teóricas como prácticas de las redes generativas antagónicas, generative adversarial networks o GANs en inglés. Fueron propuestas por primera vez por Ian Goodfellow en 2014 \cite{goodfellow2014generative}, mezclando conceptos de aprendizaje automático no supervisado, supervisado y teoría de juegos. Desde entonces han suscitado una actividad investigadora muy importante, con aplicaciones en prácticamente todos los campos relacionados con el aprendizaje automático. 
\section{Idea general}
El objetivo de las GANs, y en general de los modelos generativos, es aprender la distribución que siguen los datos, pudiendo obtener así, en última instancia, muestras de dicha distribución. En general, las distribuciones que queremos modelar son muy complejas. Supongamos que nuestro objetivo es tomar muestras de la distribución de imágenes de perros, o dicho de otro modo, generar fotos de perros que sean realistas pero que no existan en la realidad ni sean una mezcla de imágenes de nuestro conjunto de entrenamiento. Tenemos la seguridad de que la distribución es extremadamente intrincada, existen perros de distintos colores, tamaños, razas, etc. Este problema es el que van a tratar de atacar las GANs.

La idea fundamental y más novedosa detrás de las GANs es poner dos redes neuronales a competir entre sí. Una red, llamada generadora $(G)$, está dedicada a obtener imágenes a partir de ruido aleatorio con distribución $p_g(z)$, mientras que otra, llamada discriminadora $(D)$, trata de averiguar si la imagen es real o ficticia. Es frecuente ilustrar esta idea mediante la analogía de falsificadores de billetes que tratan de engañar a la policía. Los falsificadores empiezan dibujando billetes que no tienen nada que ver con los reales, intentando utilizarlos para realizar pagos, momento en el que son atrapados por la policía. Los falsificadores por tanto se dan cuenta de que están dibujando los billetes de manera incorrecta y modifican su técnica, mientras que la policía va aprendiendo a su vez a detectar mejor los billetes falsos. De este modo, a lo largo del entrenamiento se busca llegar a un equilibrio, en el que la policía no sepa discernir los billetes falsos de los verdaderos, obteniendo así los ladrones una falsificación realista. Una representación esquemática se puede ver en la Figura \ref{esquema}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{../images/report/scheme.png}
	\label{esquema}
	\caption{Diagrama conceptual de las redes generativas antagónicas.}
\end{figure}
Podemos traducir esta idea a términos matemáticos de la siguiente manera:

Para aprender la distribución $p_g$ del generador sobre los datos $x$, definimos una distribución sobre las variables de ruido de entrada $p_z(z)$. Mediante un perceptrón multicapa con parámetros $\theta_g$ definimos la función $G(z;\theta_g)$. Definimos también mediante otro perceptrón multicapa $D(x; \theta_d)$ la probabilidad de que $x$ es una muestra de los datos y no del generador. Entrenamos $D$ para que maximice la probabilidad de asignar la etiqueta correcta tanto a los ejemplos de entrenamiento como a los generados. Al mismo tiempo, entrenamos $G$ para que minimice $\log (1- D(G(z)))$. Es decir, tenemos el siguiente juego minimax:
\begin{equation}
\min_G \max_D V(D,G) = \mathbb{E} [\log D(x)] + \mathbb{E} [\log (1- D(G(z)))].
\end{equation}

En el Algoritmo \ref{alg:gan} describimos lo anterior de manera más concisa y damos una primera idea de cómo se lleva a cabo el entrenamiento.
\begin{algorithm}[h]
	\For{Iteraciones de entrenamiento}
	{
	Tomar muestra $(z^{(1)}, z^{(2)}, \ldots, z^{(m)})$ de tamaño $m$ de $p_g(z)$\;
	Tomar muestra $(x^{(1)}, x^{(2)}, \ldots, x^{(m)})$ de tamaño $m$ de $p_{d}(x)$\;
	Actualizar el discriminador ascendiendo su gradiente:
	$$
	\nabla_{\theta_d} \frac{1}{m}\sum_{i = 1}^{m}\left[\log D\left( x^{i}\right) + \log \left( 1 - D(G(z^{i}))\right) \right]
	$$
	
	Actualizar el generador ascendiendo su gradiente:
	$$
	\nabla_{\theta_g} \frac{1}{m}\sum_{i = 1}^{m} \log \left( 1 - D(G(z^{i}))\right)
	$$
	}
	\caption{Entrenamiento de una red generativa antagónica genérica.}
	\label{alg:gan}
\end{algorithm}
\section{Bases teóricas}

En esta sección realizaremos un análisis de la teoría que hay detrás de las redes generativas antagónicas. Mostraremos que el criterio de entrenamiento nos permite recuperar la distribución de los datos si damos a $G$ y $D$ capacidad suficiente. 

\begin{teorema}
	Para un generador $G$ fijo, el discriminador $D$ óptimo es:
	\begin{equation}
	D_G^*(x) = \frac{p_{datos}(x)}{p_{datos}(x) + p_g(x)}
	\end{equation}
\end{teorema}
\begin{proof}
	El discriminador busca maximizar su función de utilidad, dada por $V(G,D)$
	\begin{equation}
	\begin{aligned}
	V(G,D) &= \int_x p_{datos}(x) \log (D(x)) \mathrm{d}x + \int_z p_z(z) \log(1-D(g(z))) \mathrm{d}z\\
	&= \int_x p_{datos}(x) \log (D(x)) + p_g(x) \log (1-D(x)) \mathrm{d}x
	\end{aligned}
	\end{equation}
\end{proof}

\section{Otros modelos generativos}
Variational autoencoders, noise contrastive estimation etc.
\chapter{Generación de arte}
En esta sección nos vamos a apoyar sobre el artículo \cite{radford2015unsupervised} para implementar en \texttt{Python}, haciendo uso de \texttt{PyTorch} una red convolucional profunda generativa antagónica, con la cual vamos a tratar de generar imágenes de cuadros realistas.
\section{DCGAN}
Las redes convolucionales profundas generativas antagónicas (deep convolutional generative adversarial networks, DCGAN) son una extensión de las GANs tradicionales, que implementan una serie de recomendaciones para incrementar la estabilidad y obtener imágenes de mejor calidad. Los puntos más relevantes que se pueden extraer de \cite{radford2015unsupervised} son:
\begin{itemize}
	\item En el discriminador, utilizar convoluciones con stride en lugar de capas de pooling.
	\item En el generador, utilizar convoluciones fraccionales con stride en lugar de capas de pooling.
	\item Utilizar BatchNorm tanto para generador como discriminador.
	\item No utilizar capas fully connected.
	\item Utilizar funciones de activación ReLU en el generador, salvo para la última capa, en la que se propone usar $\tanh$.
	\item Utilizar funciones de activación LeakyReLU en el discriminador.
	\item Inicializar los pesos de ambas redes con una distribución normal.
\end{itemize}
RECORDAR QUE STRIDE Y POOL SON PARECIDOS Y DESCRIBIR LEAKYRELU.

El objetivo que nos hemos propuesto es la generación de cuadros realistas, para ello, es necesario un amplio conjunto de datos con cuadros de distintos artístas, épocas y estilos. Hemos encontrado en  una competición de Kaggle un conjunto de datos con las características deseadas, con más de 100000 imágenes, ocupando aproximadamente 49 GB. Una muestra de dichas imágenes se puede observar en la Figura \ref{img_reales}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{../images/results/original_data.png}
	\label{img_reales}
	\caption{Imágenes del conjunto de datos.}
\end{figure}

\subsection{Preprocesado}
El conjunto de datos tenía algunos defectos, como por ejemplo imágenes descargadas incorrectamente o imágenes corruptas en el propio conjunto de datos. Se ha tomado la decisión de eliminar dichas imágenes. ya que son pocas y no hay una manera directa de recuperarlas.

Una vez limpio el conjunto de datos, es necesario realizar algunas transformaciones para que, posteriormente, nuestras redes neuronales puedan utilizar las imágenes. En primer lugar hemos homogeneizado los tamaños y las proporciones. Pasamos así de cuadros de todos los tamaños y de distintas formas a cuadrados de $64\times 64$ píxeles. Posteriormente, realizamos un recorte centrado y finalmente las cargamos como tensores.

\subsection{Arquitectura}
Siguiendo las recomendaciones del artículo \cite{radford2015unsupervised}, hemos decidido utilizar la arquitectura que se muestra en la Figura \ref{esqma}. También hemos inicializado los pesos con una distribución normal $\mathcal{N}()$ y hemos seleccionado un tamaño de batch de 128.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{../images/report/architecture_scheme.png}
	\label{esqma}
	\caption{Arquitectura de las redes (Cambiar, poner tamaños de entrada y salida).}
\end{figure}
La red se ha entrenado durante 30 épocas, utilizando el algoritmo de optimización Adam \cite{kingma2014adam} con una tasa de aprendizaje de $0.0002$ y $\beta = (0.5,0.999)$.
\subsection{Recursos}
Cabe destacar que ha sido imprescindible el uso de un ordenador con GPU compatible con CUDA, en concreto se ha utilizado una Nvidia Quadro P5000. El entrenamiento de principio a fin ha tardado aproximadamente 24 horas. También se han realizado pruebas con CPU en un portátil de prestaciones modestas y se ha observado que el rendimiento era unas 20 veces menor.
\section{Resultados}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{../images/results/generated_data.png}
	\label{img_generadas}
	\caption{Imágenes generadas mediante la DCGAN implementada después de 30 épocas de entrenamiento.}
\end{figure}
\chapter{Conclusión}


\bibliography{../bibliography/tfmbib}
\bibliographystyle{abbrv}
\end{document}
